\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Background}{1}}
\newlabel{eq:forceindividual}{{1.1}{1}}
\newlabel{eq:nbodyvec}{{1.3}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Seemingly chaotic solutions to the $n$-body problem with different iniital conditions and graivational constants as solved by RK4. Note the legends ommit some masses as activity localizes away from the origin with their initial conditions.}}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Learning the $n$-body problem}{2}}
\newlabel{eq:learning}{{2.1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Deep Learning}{2}}
\newlabel{sec:dl}{{2.1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Training Neural Networks}{3}}
\newlabel{eq:gradientdescent}{{2.3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}NN-body Architecture}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Left: The loss between ground truth solution to the $n=3$-body problem and that predicted by the best neural network. Right: The predicted trajectory of the $n$-body problem at $t=0.7s$ for one-shot and iterative, red and black respectively.}}{4}}
\newlabel{fig:renormal}{{3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Left: A plot of loss \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces 2.1\hbox {}\unskip \@@italiccorr )}} as gradient descent is applied to ${\mathcal  N}_\ell $ for various different $n$.}}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Appendix}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The neural network architecture of NNBody as displayed by tensorboard. Each fully connected layer is a weight matrix multiply followed by a non-linearity.}}{6}}
